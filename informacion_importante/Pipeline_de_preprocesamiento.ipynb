{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b081aaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365cc426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def delete_regis_vo(df):\n",
    "    \"\"\"\n",
    "    Funcion que elimina los registros que tengan la vo nula\n",
    "    \"\"\"\n",
    "    df = df.dropna(subset=['RainTomorrow'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccabb30e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def binary_encoder(df):\n",
    "    \"\"\"\n",
    "    Funcion que codifica la columna RainToday en una codificacion binaria\n",
    "    \"\"\"\n",
    "    encoder = ce.BinaryEncoder(cols=['RainToday'])\n",
    "    df_decode = encoder.fit_transform(df)\n",
    "    for col in encoder.get_feature_names_out():\n",
    "        df.loc[:, col] = df_decode.loc[:, col]\n",
    "    df.drop(columns= 'RainToday', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2959441e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def outliers_replace(df):\n",
    "    \"\"\"\n",
    "    Este metodo busca los outliers de las columnas numericas con el metodo del rango intercurtilico, en caso de que algun valor\n",
    "    sea detectado como un outlier se reemplaza este valor por el percentil 25 o 75 segun sea el caso.\n",
    "    \"\"\"\n",
    "    for columna in [var for var in df.columns if df[var].dtype!='O']:\n",
    "        IQR = df[columna].quantile(0.75) - df[columna].quantile(0.25)\n",
    "        rango_inferior = df[columna].quantile(0.25) - (IQR * 1.5)\n",
    "        rango_superior = df[columna].quantile(0.75) + (IQR * 1.5)\n",
    "        df.loc[df[columna] > rango_superior, columna] = rango_superior\n",
    "        df.loc[df[columna] < rango_inferior, columna] = rango_inferior\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2bc21d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(df):\n",
    "    \"\"\"\n",
    "    Funcion que permite crear las varibles dummies en codificacion onehot\n",
    "    \"\"\"\n",
    "    ohe = OneHotEncoder()\n",
    "    cat = [columna for columna in df.columns if columna not in ['RainToday', 'RainTomorrow'] and df[columna].dtype == 'O']\n",
    "    num = [var for var in df.columns if df[var].dtype!='O']\n",
    "    binary = ['RainToday', 'RainTomorrow']\n",
    "    features = ohe.fit_transform(df[cat]).toarray()\n",
    "    features_label = ohe.categories_\n",
    "    labels = []\n",
    "    for i in range(len(features_label)):\n",
    "        label_list = np.array(features_label[i]).tolist()\n",
    "        label_name = [\"dummie_\" + str(cat[i]) + \"_\" + str(elemento) for elemento in label_list]\n",
    "        labels.extend(label_name)\n",
    "    dummies = pd.DataFrame(features, columns = labels)\n",
    "    df = pd.concat([df[num],df[binary],dummies], axis=1)\n",
    "    df_sin_nans = df.copy().filter(regex='_nan$', axis=1).columns\n",
    "    df.drop(columns=df_sin_nans, inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5c2570",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def vo_encoder(df):\n",
    "    \"\"\"\n",
    "    Funcion que codifica la variable objetivo\n",
    "    \"\"\"\n",
    "    df['RainTomorrow'] = df['RainTomorrow'].replace({'Yes': 1, 'No': 0})\n",
    "    columna_extraida = df.pop('RainTomorrow')\n",
    "    df['RainTomorrow'] = columna_extraida\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "283accea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer_vars(df):\n",
    "    num = [var for var in df.columns if df[var].dtype!='O']\n",
    "    df[num] = df[num].fillna(df[num].median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d88a9be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"D:\\Prueba_ML\\weatherAUS.csv\")\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.assign(month=data['Date'].dt.month, year=data['Date'].dt.year, day=data['Date'].dt.day).drop('Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea10bd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Repos_riesgos\\env_jupyter\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "D:\\Repos_riesgos\\env_jupyter\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
      "0          13.4     22.9       0.6          4.8       8.5           44.0   \n",
      "1           7.4     25.1       0.0          4.8       8.5           44.0   \n",
      "2          12.9     25.7       0.0          4.8       8.5           46.0   \n",
      "3           9.2     28.0       0.0          4.8       8.5           24.0   \n",
      "4          17.5     32.3       1.0          4.8       8.5           41.0   \n",
      "...         ...      ...       ...          ...       ...            ...   \n",
      "145454      3.5     21.8       0.0          4.8       8.5           31.0   \n",
      "145455      2.8     23.4       0.0          4.8       8.5           31.0   \n",
      "145456      3.6     25.3       0.0          4.8       8.5           22.0   \n",
      "145457      5.4     26.9       0.0          4.8       8.5           37.0   \n",
      "145458      7.8     27.0       0.0          4.8       8.5           28.0   \n",
      "\n",
      "        WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  \\\n",
      "0               20.0          24.0         71.0         22.0  ...   \n",
      "1                4.0          22.0         44.0         25.0  ...   \n",
      "2               19.0          26.0         38.0         30.0  ...   \n",
      "3               11.0           9.0         45.0         16.0  ...   \n",
      "4                7.0          20.0         82.0         33.0  ...   \n",
      "...              ...           ...          ...          ...  ...   \n",
      "145454          15.0          13.0         59.0         27.0  ...   \n",
      "145455          13.0          11.0         51.0         24.0  ...   \n",
      "145456          13.0           9.0         56.0         21.0  ...   \n",
      "145457           9.0           9.0         53.0         24.0  ...   \n",
      "145458          13.0           7.0         51.0         24.0  ...   \n",
      "\n",
      "        dummie_WindDir3pm_SE  dummie_WindDir3pm_SSE  dummie_WindDir3pm_SSW  \\\n",
      "0                        0.0                    0.0                    0.0   \n",
      "1                        0.0                    0.0                    0.0   \n",
      "2                        0.0                    0.0                    0.0   \n",
      "3                        0.0                    0.0                    0.0   \n",
      "4                        0.0                    0.0                    0.0   \n",
      "...                      ...                    ...                    ...   \n",
      "145454                   0.0                    0.0                    0.0   \n",
      "145455                   0.0                    0.0                    0.0   \n",
      "145456                   0.0                    0.0                    0.0   \n",
      "145457                   0.0                    0.0                    0.0   \n",
      "145458                   0.0                    0.0                    0.0   \n",
      "\n",
      "        dummie_WindDir3pm_SW  dummie_WindDir3pm_W  dummie_WindDir3pm_WNW  \\\n",
      "0                        0.0                  0.0                    1.0   \n",
      "1                        0.0                  0.0                    0.0   \n",
      "2                        0.0                  0.0                    0.0   \n",
      "3                        0.0                  0.0                    0.0   \n",
      "4                        0.0                  0.0                    0.0   \n",
      "...                      ...                  ...                    ...   \n",
      "145454                   0.0                  0.0                    0.0   \n",
      "145455                   0.0                  0.0                    0.0   \n",
      "145456                   0.0                  0.0                    0.0   \n",
      "145457                   0.0                  0.0                    0.0   \n",
      "145458                   0.0                  0.0                    0.0   \n",
      "\n",
      "        dummie_WindDir3pm_WSW  RainToday_0  RainToday_1  RainTomorrow  \n",
      "0                         0.0            0            1           0.0  \n",
      "1                         1.0            0            1           0.0  \n",
      "2                         1.0            0            1           0.0  \n",
      "3                         0.0            0            1           0.0  \n",
      "4                         0.0            0            1           0.0  \n",
      "...                       ...          ...          ...           ...  \n",
      "145454                    0.0            0            1           0.0  \n",
      "145455                    0.0            0            1           0.0  \n",
      "145456                    0.0            0            1           0.0  \n",
      "145457                    0.0            0            1           0.0  \n",
      "145458                    0.0            0            1           0.0  \n",
      "\n",
      "[144624 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "custom_transformer = FunctionTransformer(delete_regis_vo)\n",
    "custom_transformer2 = FunctionTransformer(outliers_replace)\n",
    "custom_transformer3 = FunctionTransformer(one_hot_encoder)\n",
    "custom_transformer4 = FunctionTransformer(binary_encoder)\n",
    "custom_transformer5 = FunctionTransformer(vo_encoder)\n",
    "custom_transformer6 = FunctionTransformer(imputer_vars)\n",
    "#imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "preprocesing = Pipeline(steps=[\n",
    "    (\"delete\", custom_transformer),\n",
    "    (\"outliers\", custom_transformer2),\n",
    "    (\"oneHot\", custom_transformer3),\n",
    "    (\"binary\", custom_transformer4),\n",
    "    (\"vo\", custom_transformer5),\n",
    "    (\"imputer\", custom_transformer6)\n",
    "    #(\"imputer\", imputer)\n",
    "])\n",
    "#pipeline = make_pipeline(preprocessor)\n",
    "preprocesing.fit(data)\n",
    "data_out = preprocesing.transform(data)\n",
    "print(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d90043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controls():\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        print(self.__validate_duplicate())\n",
    "        print(self.__null_values())\n",
    "        print(self.__num_columns())\n",
    "        print(self.__otuliers())\n",
    "        print(self.__cardinalidad())\n",
    "\n",
    "    def __validate_duplicate(self):\n",
    "        registros_duplicados = self.df.duplicated().sum()\n",
    "        return \"la cantidad de registros duplicados es {}\".format(registros_duplicados)\n",
    "    def __null_values(self):\n",
    "        cadena = \"\"\n",
    "        porc_nulidad = 0\n",
    "        for columna in self.df.columns:\n",
    "            suma_nulos_columna = self.df[columna].isnull().sum()\n",
    "            porcentaje_nulos_columna = (suma_nulos_columna / len(self.df)) * 100\n",
    "            porc_nulidad = porcentaje_nulos_columna + porc_nulidad\n",
    "            cadena = \"Porcentaje de valores nulos en la columna {} es {} \\n\".format(columna, porcentaje_nulos_columna) + cadena\n",
    "        if porc_nulidad == 0:\n",
    "            text = \"la nulidad es 0\"\n",
    "        else:\n",
    "            text = cadena + \"\\ncontrol fallido\"\n",
    "        return text\n",
    "    def __num_columns(self):\n",
    "        column = self.df.shape[1]\n",
    "        return \"El numero de columnas del dataframe es {}\".format(column)\n",
    "    def __otuliers(self):\n",
    "        text = \"\"\n",
    "        for column in self.df.columns:\n",
    "            if(self.df[column].max() == 1 or self.df[column].min() == 0):\n",
    "                pass\n",
    "            else:\n",
    "                IQR = self.df[column].quantile(0.75) - self.df[column].quantile(0.25)\n",
    "                rango_inferior = self.df[column].quantile(0.25) - (IQR * 1.5)\n",
    "                rango_superior = self.df[column].quantile(0.75) + (IQR * 1.5)\n",
    "                if self.df[column].max() > rango_superior or self.df[column].min() < rango_inferior:\n",
    "                    text = \"El limite superior para la variable {} es {} el inferior es {} se presentan outliers, valor mayor {}, valor menor {} \\n\".format(column, rango_superior, rango_inferior, self.df[column].max(), self.df[column].max() ) + text\n",
    "        if text == \"\":\n",
    "            return \"No hay outliers\"\n",
    "        else:\n",
    "            return text\n",
    "    def __cardinalidad(self):\n",
    "        print(\"Cardinalidad por vaiable\")\n",
    "        text = \"\"\n",
    "        for columna in self.df.columns: #cardinalidad de variables\n",
    "            text = 'columna {}: {} \\n'.format(columna, self.df[columna].nunique()) + text\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7743180a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de registros duplicados es 0\n",
      "la nulidad es 0\n",
      "El numero de columnas del dataframe es 119\n",
      "El limite superior para la variable Temp3pm es 40.3 el inferior es 2.700000000000003 se presentan outliers, valor mayor 41.099999999999994, valor menor 41.099999999999994 \n",
      "El limite superior para la variable Temp9am es 34.89999999999999 el inferior es -1.099999999999996 se presentan outliers, valor mayor 35.550000000000004, valor menor 35.550000000000004 \n",
      "El limite superior para la variable Pressure3pm es 1031.6 el inferior es 998.8000000000002 se presentan outliers, valor mayor 1034.4, valor menor 1034.4 \n",
      "El limite superior para la variable Pressure9am es 1033.8500000000001 el inferior es 1001.45 se presentan outliers, valor mayor 1036.65, valor menor 1036.65 \n",
      "El limite superior para la variable WindGustSpeed es 68.5 el inferior es 8.5 se presentan outliers, valor mayor 73.5, valor menor 73.5 \n",
      "El limite superior para la variable MaxTemp es 43.25 el inferior es 2.849999999999998 se presentan outliers, valor mayor 43.65, valor menor 43.65 \n",
      "El limite superior para la variable MinTemp es 30.2 el inferior es -5.8 se presentan outliers, valor mayor 30.6, valor menor 30.6 \n",
      "\n",
      "Cardinalidad por vaiable\n",
      "columna RainTomorrow: 2 \n",
      "columna RainToday_1: 2 \n",
      "columna RainToday_0: 2 \n",
      "columna dummie_WindDir3pm_WSW: 2 \n",
      "columna dummie_WindDir3pm_WNW: 2 \n",
      "columna dummie_WindDir3pm_W: 2 \n",
      "columna dummie_WindDir3pm_SW: 2 \n",
      "columna dummie_WindDir3pm_SSW: 2 \n",
      "columna dummie_WindDir3pm_SSE: 2 \n",
      "columna dummie_WindDir3pm_SE: 2 \n",
      "columna dummie_WindDir3pm_S: 2 \n",
      "columna dummie_WindDir3pm_NW: 2 \n",
      "columna dummie_WindDir3pm_NNW: 2 \n",
      "columna dummie_WindDir3pm_NNE: 2 \n",
      "columna dummie_WindDir3pm_NE: 2 \n",
      "columna dummie_WindDir3pm_N: 2 \n",
      "columna dummie_WindDir3pm_ESE: 2 \n",
      "columna dummie_WindDir3pm_ENE: 2 \n",
      "columna dummie_WindDir3pm_E: 2 \n",
      "columna dummie_WindDir9am_WSW: 2 \n",
      "columna dummie_WindDir9am_WNW: 2 \n",
      "columna dummie_WindDir9am_W: 2 \n",
      "columna dummie_WindDir9am_SW: 2 \n",
      "columna dummie_WindDir9am_SSW: 2 \n",
      "columna dummie_WindDir9am_SSE: 2 \n",
      "columna dummie_WindDir9am_SE: 2 \n",
      "columna dummie_WindDir9am_S: 2 \n",
      "columna dummie_WindDir9am_NW: 2 \n",
      "columna dummie_WindDir9am_NNW: 2 \n",
      "columna dummie_WindDir9am_NNE: 2 \n",
      "columna dummie_WindDir9am_NE: 2 \n",
      "columna dummie_WindDir9am_N: 2 \n",
      "columna dummie_WindDir9am_ESE: 2 \n",
      "columna dummie_WindDir9am_ENE: 2 \n",
      "columna dummie_WindDir9am_E: 2 \n",
      "columna dummie_WindGustDir_WSW: 2 \n",
      "columna dummie_WindGustDir_WNW: 2 \n",
      "columna dummie_WindGustDir_W: 2 \n",
      "columna dummie_WindGustDir_SW: 2 \n",
      "columna dummie_WindGustDir_SSW: 2 \n",
      "columna dummie_WindGustDir_SSE: 2 \n",
      "columna dummie_WindGustDir_SE: 2 \n",
      "columna dummie_WindGustDir_S: 2 \n",
      "columna dummie_WindGustDir_NW: 2 \n",
      "columna dummie_WindGustDir_NNW: 2 \n",
      "columna dummie_WindGustDir_NNE: 2 \n",
      "columna dummie_WindGustDir_NE: 2 \n",
      "columna dummie_WindGustDir_N: 2 \n",
      "columna dummie_WindGustDir_ESE: 2 \n",
      "columna dummie_WindGustDir_ENE: 2 \n",
      "columna dummie_WindGustDir_E: 2 \n",
      "columna dummie_Location_Woomera: 2 \n",
      "columna dummie_Location_Wollongong: 2 \n",
      "columna dummie_Location_Witchcliffe: 2 \n",
      "columna dummie_Location_Williamtown: 2 \n",
      "columna dummie_Location_Watsonia: 2 \n",
      "columna dummie_Location_Walpole: 2 \n",
      "columna dummie_Location_WaggaWagga: 2 \n",
      "columna dummie_Location_Uluru: 2 \n",
      "columna dummie_Location_Tuggeranong: 2 \n",
      "columna dummie_Location_Townsville: 2 \n",
      "columna dummie_Location_SydneyAirport: 2 \n",
      "columna dummie_Location_Sydney: 2 \n",
      "columna dummie_Location_SalmonGums: 2 \n",
      "columna dummie_Location_Sale: 2 \n",
      "columna dummie_Location_Richmond: 2 \n",
      "columna dummie_Location_Portland: 2 \n",
      "columna dummie_Location_PerthAirport: 2 \n",
      "columna dummie_Location_Perth: 2 \n",
      "columna dummie_Location_Penrith: 2 \n",
      "columna dummie_Location_PearceRAAF: 2 \n",
      "columna dummie_Location_Nuriootpa: 2 \n",
      "columna dummie_Location_NorfolkIsland: 2 \n",
      "columna dummie_Location_NorahHead: 2 \n",
      "columna dummie_Location_Nhil: 2 \n",
      "columna dummie_Location_Newcastle: 2 \n",
      "columna dummie_Location_MountGinini: 2 \n",
      "columna dummie_Location_MountGambier: 2 \n",
      "columna dummie_Location_Moree: 2 \n",
      "columna dummie_Location_Mildura: 2 \n",
      "columna dummie_Location_MelbourneAirport: 2 \n",
      "columna dummie_Location_Melbourne: 2 \n",
      "columna dummie_Location_Launceston: 2 \n",
      "columna dummie_Location_Katherine: 2 \n",
      "columna dummie_Location_Hobart: 2 \n",
      "columna dummie_Location_GoldCoast: 2 \n",
      "columna dummie_Location_Darwin: 2 \n",
      "columna dummie_Location_Dartmoor: 2 \n",
      "columna dummie_Location_CoffsHarbour: 2 \n",
      "columna dummie_Location_Cobar: 2 \n",
      "columna dummie_Location_Canberra: 2 \n",
      "columna dummie_Location_Cairns: 2 \n",
      "columna dummie_Location_Brisbane: 2 \n",
      "columna dummie_Location_Bendigo: 2 \n",
      "columna dummie_Location_Ballarat: 2 \n",
      "columna dummie_Location_BadgerysCreek: 2 \n",
      "columna dummie_Location_AliceSprings: 2 \n",
      "columna dummie_Location_Albury: 2 \n",
      "columna dummie_Location_Albany: 2 \n",
      "columna dummie_Location_Adelaide: 2 \n",
      "columna day: 31 \n",
      "columna year: 11 \n",
      "columna month: 12 \n",
      "columna Temp3pm: 393 \n",
      "columna Temp9am: 374 \n",
      "columna Cloud3pm: 10 \n",
      "columna Cloud9am: 10 \n",
      "columna Pressure3pm: 388 \n",
      "columna Pressure9am: 382 \n",
      "columna Humidity3pm: 101 \n",
      "columna Humidity9am: 83 \n",
      "columna WindSpeed3pm: 23 \n",
      "columna WindSpeed9am: 21 \n",
      "columna WindGustSpeed: 38 \n",
      "columna Sunshine: 145 \n",
      "columna Evaporation: 146 \n",
      "columna Rainfall: 21 \n",
      "columna MaxTemp: 414 \n",
      "columna MinTemp: 367 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Controls at 0x2c6bacf3a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Controls(data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b197b",
   "metadata": {},
   "source": [
    "Model, la metrica que usaremos sera la precision de la predicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6172dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separacion de variable objetivo\n",
    "x = data_out.drop(['RainTomorrow'], axis=1)\n",
    "y = data_out['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6d777dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f972ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#escalado de datos\n",
    "scaler = MinMaxScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d55e6e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando RandomForest\n",
      "Precisión en el conjunto de prueba para RandomForest: 0.8592, tiempo de ejecucion: 57.61011528968811\n",
      "\n",
      "Entrenando logreg\n",
      "Precisión en el conjunto de prueba para logreg: 0.8529, tiempo de ejecucion: 4.378999948501587\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Repos_riesgos\\env_jupyter\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    ('RandomForest', RandomForestClassifier()),\n",
    "    ('logreg', LogisticRegression())\n",
    "]\n",
    "for model_name, model in models:\n",
    "    print(f\"Entrenando {model_name}\")\n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Precisión en el conjunto de prueba para {model_name}: {accuracy:.4f}, tiempo de ejecucion: {training_time}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc05a0",
   "metadata": {},
   "source": [
    "Nos quedaremos con la regresion, ambos algoritmos tienen una presicion similar. Ahora implemetaremos una malla de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4adda66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'C': 1, 'max_iter': 500, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear'}\n",
      "Mejor puntaje de precisión: 0.8479762035860564\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [1, 10, 100, 500],  # Parámetro de regularización\n",
    "    'random_state': [0],\n",
    "    'penalty': ['l2'],\n",
    "    'max_iter': [500],\n",
    "    'solver': ['liblinear','lbfgs'],     # Método de solución\n",
    "}\n",
    "logreg = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=3)\n",
    "grid_search.fit(x_train, y_train)\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor puntaje de precisión:\", grid_search.best_score_)\n",
    "report = classification_report(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9a9adae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros: {'C': 1, 'max_iter': 500, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear'}\n",
      "Puntaje medio: 0.8479762035860564\n",
      "\n",
      "Parámetros: {'C': 1, 'max_iter': 500, 'penalty': 'l2', 'random_state': 0, 'solver': 'lbfgs'}\n",
      "Puntaje medio: 0.8477860542638175\n",
      "\n",
      "Parámetros: {'C': 10, 'max_iter': 500, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear'}\n",
      "Puntaje medio: 0.8479762022414055\n",
      "\n",
      "Parámetros: {'C': 10, 'max_iter': 500, 'penalty': 'l2', 'random_state': 0, 'solver': 'lbfgs'}\n",
      "Puntaje medio: 0.8479675590496476\n",
      "\n",
      "Parámetros: {'C': 100, 'max_iter': 500, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear'}\n",
      "Puntaje medio: 0.847881128028503\n",
      "\n",
      "Parámetros: {'C': 100, 'max_iter': 500, 'penalty': 'l2', 'random_state': 0, 'solver': 'lbfgs'}\n",
      "Puntaje medio: 0.8478811284767199\n",
      "\n",
      "Parámetros: {'C': 500, 'max_iter': 500, 'penalty': 'l2', 'random_state': 0, 'solver': 'liblinear'}\n",
      "Puntaje medio: 0.847881128028503\n",
      "\n",
      "Parámetros: {'C': 500, 'max_iter': 500, 'penalty': 'l2', 'random_state': 0, 'solver': 'lbfgs'}\n",
      "Puntaje medio: 0.8479157007955345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = grid_search.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(\"Parámetros:\", params)\n",
    "    print(\"Puntaje medio:\", mean_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c587f7e",
   "metadata": {},
   "source": [
    "Al comparar los resultados de la malla de hiperparametros, se evidencia que el modelo se desempeña mejor con los hiperparametros por default solo se aumentara el numero de iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb720b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter = 500, C = 1, solver = 'liblinear', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1d183fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=500, random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2faccc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = logreg.predict(x_test)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8cbd8705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = logreg.predict(x_train)\n",
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2e17107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_test = accuracy_score(y_test, y_pred_test)\n",
    "recall_test = accuracy_score(y_test[y_test == 1], y_pred_test[y_test == 1])\n",
    "precision_train = accuracy_score(y_train, y_pred_train)\n",
    "recall_train = accuracy_score(y_train[y_train == 1], y_pred_train[y_train == 1])\n",
    "\n",
    "# Calcular AUC\n",
    "auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "# Crear el DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Metric': ['Precision model_test', 'Recall_test', 'Precision model_train', 'Recall_train', 'Auc_test', 'Auc_train'],\n",
    "    'Value': [precision_test, recall_test, precision_train, recall_train, auc_test, auc_train]\n",
    "})\n",
    "\n",
    "df.to_excel(\"metrics_model.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df42ce2",
   "metadata": {},
   "source": [
    "El modelo no se ve con overfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0de7b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.95      0.91     90128\n",
      "         1.0       0.73      0.50      0.59     25571\n",
      "\n",
      "    accuracy                           0.85    115699\n",
      "   macro avg       0.80      0.72      0.75    115699\n",
      "weighted avg       0.84      0.85      0.84    115699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_train, y_pred_train)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7953d95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21457  1162]\n",
      " [ 3094  3212]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f1dfa4",
   "metadata": {},
   "source": [
    " #Conclusiones\n",
    " . El modelo presenta una buena capacidad de predecir los 0 pero no tanto para los 1.\n",
    " . El modelo tiene una roc aceptablemente buena.\n",
    " . La buenas metricas de precision son gracias a la buena capacidad de predecir los ceros\n",
    " . Se puede tratar de mover el umbral de decision si lo que se quiere es predecir mas 1 que 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6b90354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('RainModel.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
